{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63c5acd-f4cd-4eeb-9759-a84a46ae9d7a",
   "metadata": {},
   "source": [
    "# Welcome to Zoopla Scraper\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This Python-based notebook is designed to accept any Zoopla search query, and automatically scrape all details from the corresponding listings into *csv* files for further analysis.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This should be fairly easy to use with no other prerequisites, although this is fairly experimental, so expect error messages. Basic technical fluency will help in diagnosing these, particuarly knowledge of Python and HTML - JavaScript could also be useful.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Most of the cells below can be ignored by a non-expert user - Cells which can be customised are clearly marked. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e418f4b-1337-4a16-ae3a-c06915cc18a7",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "These cells install required additional packages.\n",
    "\n",
    "* '_bs4_' is *Beautiful Soup*, a package which helps with retrieving HTML content.\n",
    "* '_lxml_' is a package for efficiently parsing XML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5085a3a5-200a-4a75-a639-a61a00186096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3cef23-536a-4dcb-8827-f42e392e8824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in /Users/matthew/Library/Python/3.8/lib/python/site-packages (4.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c00b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/matthew/Library/Python/3.8/lib/python/site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests) (2.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b57542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.4.1-cp38-cp38-macosx_10_9_x86_64.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.18.5\n",
      "  Downloading numpy-1.22.2-cp38-cp38-macosx_10_14_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/matthew/Library/Python/3.8/lib/python/site-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/Users/matthew/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-1.22.2 pandas-1.4.1 pytz-2021.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6aa20a-a644-4285-aab5-2dc82a335b9f",
   "metadata": {},
   "source": [
    "## Package Imports\n",
    "\n",
    "In addition to the installed prerequisites, there are other components of the Python library imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d750c9c9-793d-4caf-839f-dbf70ebaed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784d6da-b0d9-4f20-ba35-75b9b22f8d73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Search Link Input\n",
    "\n",
    "Simply go to Zoopla, design a search query, and paste it below. Do note that if your search term returns more than 25 results, you'll need to customise the page size.\n",
    "\n",
    "Note the usage of `size=100` below - This ensures that all returned results will be on one page.\n",
    "\n",
    "`https://www.zoopla.co.uk/to-rent/flats/e14/?include_rented=true&include_shared_accommodation=false&page_`**size=100**``&polyenc=uglyHmn@{BxCVlElDlEpDz@`FFbB|Aj@`DnElA~CoBtDfArEsf@oI{CcD|EmBfOc@f@kAy@{HqGqDm@&price_frequency=per_month&view_type=list&q=E14&radius=0&results_sort=most_reduced&search_source=facets``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56dcb38-d542-4e62-9322-cc8b27f4541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_link = 'https://www.zoopla.co.uk/to-rent/flats/e14/?include_rented=true&include_shared_accommodation=false&page_size=100&polyenc=uglyHmn@{BxCVlElDlEpDz@`FFbB|Aj@`DnElA~CoBtDfArEsf@oI{CcD|EmBfOc@f@kAy@{HqGqDm@&price_frequency=per_month&view_type=list&q=E14&radius=0&results_sort=most_reduced&search_source=facets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f04d3-38f2-4296-bd3c-eb899929fe08",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n",
    "The cells step through the following:\n",
    "\n",
    "* Go and fetch the search results HTML\n",
    "* Extract the URLs for each listing to create a 'links list'\n",
    "* Visit each URL to pull the HTML of the individual listings\n",
    "* Extract the 'listingDetails' data object that Zoopla retrieves as a GraphQL query via the Apollo Client (luckily the result is simply appended to the HTML of the listing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda3d619-0b60-44da-b9f3-1fb6d58e9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_page = requests.get(search_link)\n",
    "bsobj = soup(search_page.content,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c093474-eabd-423e-a41e-5ad11c023dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_list = []\n",
    "for result in bsobj.findAll('a',{'data-testid':'listing-details-link'}):\n",
    "    root_node = ET.fromstring(str(result))\n",
    "    links_list.append('https://www.zoopla.co.uk' + root_node.get('href')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef201168-4b85-4f2e-98a2-4c1451fe6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "listingDetails_list = []\n",
    "\n",
    "for listing in links_list:\n",
    "    listing_page = requests.get(listing)\n",
    "    bsobj = soup(listing_page.content,'lxml')\n",
    "    \n",
    "    json_props = json.loads(bsobj.findAll('script')[-1].getText())\n",
    "    listingDetails = json_props['props']['pageProps']['listingDetails']\n",
    "    \n",
    "    listingDetails_list.append(listingDetails) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00643f-1a65-4b94-9ebf-032b62911349",
   "metadata": {},
   "source": [
    "## Data Parsing\n",
    "\n",
    "With all the data retrieved, it can now be split into its component parts. This is because some of them have different structures, and need slightly unique treatment to include into the main data object\n",
    "\n",
    "The data is eventually combined into Pandas dataframes, and then converted into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76985f3b-2584-495a-82f8-528e67fc7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_df_list = []\n",
    "\n",
    "for listingDetail in listingDetails_list:\n",
    "\n",
    "    adTargeting = listingDetail['adTargeting']\n",
    "    branch = listingDetail['branch']\n",
    "    feature_bullets = listingDetail['features']['bullets']\n",
    "    feature_flags = listingDetail['features']['flags']\n",
    "    viewCount = listingDetail['viewCount']\n",
    "    pricing = listingDetail['pricing']\n",
    "    \n",
    "    if 'alternateRentFrequencyPrice' in pricing:\n",
    "        del pricing['alternateRentFrequencyPrice']\n",
    "    \n",
    "    listingId = adTargeting['listingId']\n",
    "\n",
    "    adTargeting_df = pd.DataFrame.from_dict(adTargeting, orient='index', columns=[0]).transpose()\n",
    "    branch_df = pd.DataFrame.from_dict(branch, orient='index', columns=[0]).transpose()\n",
    "    feature_flags_df = pd.DataFrame.from_dict(feature_flags, orient='index', columns=[0]).transpose()\n",
    "    viewCount_df = pd.DataFrame.from_dict(viewCount, orient='index', columns=[0]).transpose()\n",
    "    pricing_df = pd.DataFrame.from_dict(pricing, orient='index', columns=[0]).transpose()\n",
    "\n",
    "    master_df = pd.concat(objs = [adTargeting_df,branch_df,feature_flags_df,viewCount_df,pricing_df], axis = 1)\n",
    "    \n",
    "    master_df['feature_bullets'] = ', '.join(feature_bullets)\n",
    "    \n",
    "    listing_df_list.insert(0, master_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59386371-93be-45de-a279-0acddc5f4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "priceHistory_df_list = []\n",
    "\n",
    "for listingDetail in listingDetails_list:\n",
    "    \n",
    "    priceChanges = listingDetail['priceHistory']['priceChanges']\n",
    "    listingId = listingDetail['adTargeting']['listingId']\n",
    "    \n",
    "    if not priceChanges is None:\n",
    "        for priceChange in priceChanges:\n",
    "            priceChange['listingId'] = listingId\n",
    "    \n",
    "            priceChanges_df = pd.DataFrame.from_dict(priceChange, orient='index', columns=[0]).transpose()\n",
    "            priceHistory_df_list.insert(0, priceChanges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4ebc35-c3e0-4a25-823b-1c87f10ec806",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(objs = listing_df_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f00f09-ec31-47bb-851f-d432c3012c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_priceHistory_df = pd.concat(objs = priceHistory_df_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37627266-e1c2-4a1e-a119-5451f87e37e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-02-2022_1504\n"
     ]
    }
   ],
   "source": [
    "date_extracted = datetime.datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "print(date_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b9a1ee-5dec-4e2f-9c6e-b207423b89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('master_' + date_extracted + '.csv', index=False)\n",
    "master_priceHistory_df.to_csv('master_priceHistory_' + date_extracted + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
